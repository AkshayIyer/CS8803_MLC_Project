{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rFjye9DNPN3B",
        "outputId": "b97453c6-f684-4844-fa62-ed14816aef83"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting ase\n",
            "  Downloading ase-3.22.1-py3-none-any.whl (2.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m19.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.10/dist-packages (from ase) (1.22.4)\n",
            "Requirement already satisfied: matplotlib>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from ase) (3.7.1)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from ase) (1.10.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.1.0->ase) (1.0.7)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.1.0->ase) (4.39.3)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.1.0->ase) (23.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.1.0->ase) (1.4.4)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.1.0->ase) (8.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.1.0->ase) (3.0.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.1.0->ase) (2.8.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.1.0->ase) (0.11.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.1.0->ase) (1.16.0)\n",
            "Installing collected packages: ase\n",
            "Successfully installed ase-3.22.1\n"
          ]
        }
      ],
      "source": [
        "!pip install ase"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pt2VaFRNyG_Z",
        "outputId": "254e92ab-f870-4463-8a6f-8c60c7737561"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.0.0+cu118\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "print(torch.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o6z_hzs9PuY2",
        "outputId": "0533fd30-a4ab-4f48-dc30-fc9b84406266"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.2/10.2 MB\u001b[0m \u001b[31m21.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.8/4.8 MB\u001b[0m \u001b[31m43.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for torch_geometric (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "!pip install -q torch-scatter -f https://data.pyg.org/whl/torch-2.0.0+cu118.html\n",
        "!pip install -q torch-sparse -f https://data.pyg.org/whl/torch-2.0.0+cu118.html\n",
        "!pip install -q git+https://github.com/pyg-team/pytorch_geometric.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "zMttg7jFOs2g"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import ase\n",
        "from ase import Atoms\n",
        "import ase.neighborlist\n",
        "\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch.nn import GRU, Linear, ReLU, Sequential\n",
        "\n",
        "from torch_geometric.loader import DataLoader\n",
        "from torch_geometric.nn import  global_mean_pool, CGConv\n",
        "from torch_geometric.data import DataLoader, Dataset, Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "XBDW39-TOqNs",
        "outputId": "1217a41f-9a62-4acb-980a-b029e481215b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\ndataSetLen = len(data_list)\\nstartTrainIdx = 0\\nendTrainIdx = int(dataSetLen * 0.75)\\n\\nstartValIdx = endTrainIdx\\nendValIdx = int(dataSetLen * 0.8)\\n\\nstartTestIdx = endValIdx\\nendTestIdx = dataSetLen\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "dim = 60\n",
        "cutoff = 10\n",
        "batch_size = 64 \n",
        "epochs = 20\n",
        "\n",
        "def aseAtomsBuilder(filename):\n",
        "#Using the preprocessing from the the example code to help with downstream tasks\n",
        "\n",
        "  #Read json file\n",
        "  json_path = filename\n",
        "  f = open(json_path)\n",
        "  structures = json.load(f)\n",
        "  f.close()\n",
        "\n",
        "  data_list = []\n",
        "  for i, s in enumerate(structures): \n",
        "      data = Data()\n",
        "      \n",
        "      #construct ASE atoms object to compute neighbors and distances\n",
        "      atoms = Atoms(numbers = s[\"atomic_numbers\"], positions = s[\"positions\"], cell = s[\"cell\"])\n",
        "      idx0, idx1, distance = ase.neighborlist.neighbor_list(\n",
        "          \"ijd\",\n",
        "          atoms,\n",
        "          cutoff=cutoff,\n",
        "          self_interaction=True,\n",
        "      )\n",
        "      \n",
        "      data.edge_index = torch.stack([torch.LongTensor(idx0), torch.LongTensor(idx1)], dim=0)\n",
        "      data.edge_attr = torch.tensor(distance).unsqueeze(-1).float()\n",
        "      data.x = torch.tensor(s[\"atomic_numbers\"]).unsqueeze(-1).float()\n",
        "      data.y = torch.tensor([s[\"y\"]])\n",
        "      \n",
        "      data_list.append(data)\n",
        "\n",
        "  #Split into train, test, val\n",
        "\n",
        "  return data_list\n",
        "\n",
        "'''\n",
        "dataSetLen = len(data_list)\n",
        "startTrainIdx = 0\n",
        "endTrainIdx = int(dataSetLen * 0.75)\n",
        "\n",
        "startValIdx = endTrainIdx\n",
        "endValIdx = int(dataSetLen * 0.8)\n",
        "\n",
        "startTestIdx = endValIdx\n",
        "endTestIdx = dataSetLen\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "TXc7jX1XtAV3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "60cd178c-314b-4e1d-d4a3-0d0b24c181d3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5368\n",
            "671\n",
            "671\n"
          ]
        }
      ],
      "source": [
        "f = open(\"train_data.json\")\n",
        "trainRawData = json.load(f)\n",
        "f.close()\n",
        "\n",
        "f = open(\"val_data.json\")\n",
        "valRawData = json.load(f)\n",
        "f.close()\n",
        "\n",
        "f = open(\"test_data.json\")\n",
        "testRawData = json.load(f)\n",
        "f.close()\n",
        "\n",
        "print(len(trainRawData))\n",
        "print(len(valRawData))\n",
        "print(len(testRawData))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "8udZuLdadD5N"
      },
      "outputs": [],
      "source": [
        "#Hyperparameters\n",
        "batch_size = 64\n",
        "num_workers = 0\n",
        "depth = 2\n",
        "divisor = 3\n",
        "p1 = 0.3\n",
        "p2 = 0.3\n",
        "p3 = 0.3\n",
        "hidden_channels = 150\n",
        "lr = 0.0001\n",
        "persistentWorkers = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dwl9DRqsvuJT",
        "outputId": "ac7cbc32-49de-47a9-a338-0d5fdbda4fb4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "671\n",
            "671\n"
          ]
        }
      ],
      "source": [
        "import os.path as osp\n",
        "\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from torch_geometric.loader import ShaDowKHopSampler\n",
        "from torch_geometric.nn import SAGEConv, global_mean_pool, TransformerConv, GATv2Conv, ChebConv, TAGConv\n",
        "\n",
        "train_data = aseAtomsBuilder(\"train_data.json\")\n",
        "val_data = aseAtomsBuilder(\"val_data.json\")\n",
        "test_data = aseAtomsBuilder(\"test_data.json\")\n",
        "\n",
        "\n",
        "kwargs = {'batch_size': batch_size, 'num_workers': num_workers, 'persistent_workers': persistentWorkers}\n",
        "\n",
        "train_loader = []\n",
        "val_loader = []\n",
        "test_loader = []\n",
        "\n",
        "currIdx = 0\n",
        "for x in train_data:\n",
        "  totalNodes = len(trainRawData[currIdx][\"positions\"])\n",
        "  train_loader.append(ShaDowKHopSampler(x, depth=depth, num_neighbors=50 // divisor, **kwargs))\n",
        "\n",
        "currIdx = 0\n",
        "for y in val_data:\n",
        "  totalNodes = len(valRawData[currIdx][\"positions\"])\n",
        "  val_loader.append(ShaDowKHopSampler(y, depth=depth, num_neighbors = totalNodes // divisor, **kwargs))\n",
        "\n",
        "currIdx = 0\n",
        "for z in test_data:\n",
        "  totalNodes = len(testRawData[currIdx][\"positions\"])\n",
        "  test_loader.append(ShaDowKHopSampler(z, depth=depth, num_neighbors = totalNodes // divisor, **kwargs))\n",
        "\n",
        "print(len(val_loader))\n",
        "print(len(test_loader))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for d in train_loader[0]:\n",
        "  print(d)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wZrZZTiu1KEn",
        "outputId": "fffa62fc-c9b6-4d02-d753-f5720799bce4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DataBatch(batch=[64], ptr=[9], root_n_id=[8], edge_index=[2, 512], edge_attr=[512, 1], x=[64, 1], y=[1, 1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "NMOTpV9QABqw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for d in train_loader[0]:\n",
        "  for b in d:\n",
        "    print(Data(b))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wy7w4o3CCaxe",
        "outputId": "9ceb6f44-67d1-4d13-f196-2d5950c82a9e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data(x=[2])\n",
            "Data(x=[2])\n",
            "Data(x=[2])\n",
            "Data(x=[2])\n",
            "Data(x=[2])\n",
            "Data(x=[2])\n",
            "Data(x=[2])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.hist([len(k) for k in val_loader])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 486
        },
        "id": "XrVshmHl_UB1",
        "outputId": "05f54c2b-7790-43fb-c2c9-039742e66df0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([669.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   2.]),\n",
              " array([1. , 1.1, 1.2, 1.3, 1.4, 1.5, 1.6, 1.7, 1.8, 1.9, 2. ]),\n",
              " <BarContainer object of 10 artists>)"
            ]
          },
          "metadata": {},
          "execution_count": 33
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 380
        },
        "id": "0L_WGNhlF9cc",
        "outputId": "c550fac7-a218-4702-84a2-f679b541846e"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-f9018d7ce74f>\u001b[0m in \u001b[0;36m<cell line: 81>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     83\u001b[0m     \u001b[0mval_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m     \u001b[0mtest_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-15-f9018d7ce74f>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0mformattedData\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msubData\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubData\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubData\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0medge_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubData\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubData\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroot_n_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ml1_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubData\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-15-f9018d7ce74f>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, edge_index, batch, root_n_id)\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mroot_n_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mp1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch_geometric/nn/conv/cheb_conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, edge_index, edge_weight, batch, lambda_max)\u001b[0m\n\u001b[1;32m    149\u001b[0m     ) -> Tensor:\n\u001b[1;32m    150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 151\u001b[0;31m         edge_index, norm = self.__norm__(\n\u001b[0m\u001b[1;32m    152\u001b[0m             \u001b[0medge_index\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m             \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnode_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch_geometric/nn/conv/cheb_conv.py\u001b[0m in \u001b[0;36m__norm__\u001b[0;34m(self, edge_index, num_nodes, edge_weight, normalization, lambda_max, dtype, batch)\u001b[0m\n\u001b[1;32m    117\u001b[0m         \u001b[0mbatch\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptTensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m     ):\n\u001b[0;32m--> 119\u001b[0;31m         edge_index, edge_weight = get_laplacian(edge_index, edge_weight,\n\u001b[0m\u001b[1;32m    120\u001b[0m                                                 \u001b[0mnormalization\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m                                                 num_nodes)\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch_geometric/utils/get_laplacian.py\u001b[0m in \u001b[0;36mget_laplacian\u001b[0;34m(edge_index, edge_weight, normalization, dtype, num_nodes)\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m         \u001b[0;31m# L = I - A_norm.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m         edge_index, tmp = add_self_loops(edge_index, -edge_weight,\n\u001b[0m\u001b[1;32m     85\u001b[0m                                          fill_value=1., num_nodes=num_nodes)\n\u001b[1;32m     86\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mtmp\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch_geometric/utils/loop.py\u001b[0m in \u001b[0;36madd_self_loops\u001b[0;34m(edge_index, edge_attr, fill_value, num_nodes)\u001b[0m\n\u001b[1;32m    165\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 167\u001b[0;31m def add_self_loops(\n\u001b[0m\u001b[1;32m    168\u001b[0m     \u001b[0medge_index\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m     \u001b[0medge_attr\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptTensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "\n",
        "class GNN(torch.nn.Module):\n",
        "    def __init__(self, in_channels, hidden_channels, out_channels):\n",
        "        super().__init__()\n",
        "        self.out_channels = out_channels\n",
        "        self.conv1 = ChebConv(in_channels, hidden_channels, 5)\n",
        "        self.conv2 = TAGConv(hidden_channels, hidden_channels)\n",
        "        self.conv3 = TransformerConv(hidden_channels, hidden_channels)\n",
        "        self.lin1 = torch.nn.Linear(2 * hidden_channels, out_channels)\n",
        "        self.softmax = torch.nn.Softmax(dim = 0)\n",
        "        self.lin2 = torch.nn.Linear(out_channels, out_channels)\n",
        "      \n",
        "\n",
        "    def forward(self, x, edge_index, batch, root_n_id):\n",
        "        \n",
        "        x = self.conv1(x, edge_index).relu()\n",
        "        x = F.dropout(x, p=p1)\n",
        "        x = self.conv2(x, edge_index).relu()\n",
        "        x = F.dropout(x, p=p2, training=self.training)\n",
        "        x = self.conv3(x, edge_index).relu()\n",
        "        x = F.dropout(x, p=p3, training=self.training)\n",
        "\n",
        "        # We merge both central node embeddings and subgraph embeddings:\n",
        "        x = torch.cat([x[root_n_id], global_mean_pool(x, batch)], dim=-1)\n",
        "        x = self.lin1(x)\n",
        "        x  = self.softmax(x)\n",
        "        x = self.lin2(x)\n",
        "        \n",
        "        return x.mean(axis = 0).unsqueeze(-1)\n",
        "\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = GNN(1, hidden_channels, 1).to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "\n",
        "\n",
        "def train():\n",
        "    model.train()\n",
        "    total_loss = total_examples = 0\n",
        "    \n",
        "    count = 0\n",
        "    for data in train_loader:\n",
        "      \n",
        "      for subData in data:\n",
        "\n",
        "        formattedData = subData.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        out = model(subData.x, subData.edge_index, subData.batch, subData.root_n_id)\n",
        "        loss = F.l1_loss(out, subData.y)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += float(loss) * subData.num_graphs\n",
        "        total_examples += subData.num_graphs\n",
        "\n",
        "    return total_loss / total_examples\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def test(loader):\n",
        "    model.eval()\n",
        "    loss_all = 0\n",
        "    minPrediction = 100\n",
        "    maxPrediction = -5\n",
        "\n",
        "    for data in loader:\n",
        "      for subData in data:\n",
        "        subData = subData.to(device)\n",
        "        out = model(subData.x, subData.edge_index, subData.batch, subData.root_n_id)\n",
        "\n",
        "        if out[0][0] < minPrediction:\n",
        "          minPrediction = out[0][0]\n",
        "        \n",
        "        elif out[0][0] > maxPrediction:\n",
        "          maxPrediction = out[0][0]\n",
        "\n",
        "        loss = F.l1_loss(out, subData.y)\n",
        "        loss_all += loss.item() * subData.num_graphs\n",
        "\n",
        "    return loss_all / len(loader)\n",
        "\n",
        "\n",
        "for epoch in range(1, 3):\n",
        "    loss = train()\n",
        "    val_acc = test(val_loader)\n",
        "    test_acc = test(test_loader)\n",
        "    print(f'Epoch: {epoch:02d}, Loss: {loss:.4f}, ',\n",
        "          f'Val: {val_acc:.4f} Test: {test_acc:.4f}')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}